{
  "version": "0.2.0",
  "configurations": [
    {
      "type": "bashdb",
      "request": "launch",
      "name": "Bash-Debug (select script from list of sh files)",
      "cwd": "${workspaceFolder}",
      "program": "${command:SelectScriptName}",
      "args": []
    },

    {
      "name": "Python: clouddesk dataset_info.py",
      "type": "python",
      "request": "launch",
      "program": "./Kg2text/data_utils/dataset_info.py",
      "console": "integratedTerminal",
      "args": [
        "--file_name", 
        "trial00",
        "--data_dir", 
        "/home/xianjiay/efs-storage/data-bin/dataset",
        "--dataset", 
        "kgtext_wikidata",
        "--option", "info",
        "--unit", "10000"
      ],
      "env": {
        "PYTHONPATH": "${workspaceRoot}"
      },
      "envFile": "${workspaceFolder}/.env"
    },
    {
      "name": "Python: aws: create_dataset.py",
      "type": "python",
      "request": "launch",
      "program": "./Kg2text/code/create_dataset.py",
      "console": "integratedTerminal",
      "args": [
        "--option",
        "kg2kg",
        "--seperate",
        "",
        "--text_only",
        "",
        "--simple",
        "",
        "--tokenized",
        "True",
        "--tagged",
        "True",
        "--dataset",
        "kgtext_wikidata",
        "--add_eos",
        "",
        "--add_bos",
        "",
        "--add_kg_tag",
        "True",
        "--add_text_tag",
        "True",
        "--add_lang_tag",
        "True",
        "--lang",
        "en_XX",
        "--config_file",
        "triples_dataset.yaml",
        "--setting_file",
        "token_setting.yaml",
        "--load_data_dir",
        "/home/ubuntu/efs-storage/data-bin/dataset",
        "--save_data_dir",
        "/home/ubuntu/efs-storage/data-bin/dataset_denoising",
        "--efs",
        "/home/ubuntu/efs-storage"
      ],
      "env": {
        "PYTHONPATH": "${workspaceRoot}"
      },
      "envFile": "${workspaceFolder}/.env"
    },
    {
      "name": "Python: clouddesk: create_dataset.py",
      "type": "python",
      "request": "launch",
      "program": "./Kg2text/code/create_dataset.py",
      "console": "integratedTerminal",
      "args": [
        "--option",
        "kg2kg",
        "--seperate",
        "",
        "--text_only",
        "",
        "--simple",
        "",
        "--tokenized",
        "True",
        "--tagged",
        "True",
        "--dataset",
        "kgtext_wikidata",
        "--add_eos",
        "",
        "--add_bos",
        "",
        "--add_kg_tag",
        "True",
        "--add_text_tag",
        "True",
        "--add_lang_tag",
        "True",
        "--lang",
        "en_XX",
        "--config_file",
        "triples_dataset.yaml",
        "--setting_file",
        "token_setting.yaml",
        "--load_data_dir",
        "/home/xianjiay/efs-storage/data-bin/dataset",
        "--save_data_dir",
        "/home/xianjiay/efs-storage/data-bin/dataset_denoising",
        "--efs",
        "/home/xianjiay/efs-storage"
      ],
      "env": {
        "PYTHONPATH": "${workspaceRoot}"
      },
      "envFile": "${workspaceFolder}/.env"
    },
    {
      "name": "Python: metric",
      "type": "python",
      "request": "launch",
      "program": "/home/ubuntu/Data-to-text-Evaluation-Metric/measure_scores.py",
      "console": "integratedTerminal",
      "args": [
        "/home/ubuntu/efs-storage/dataset/webnlg/test.txt",
        "/home/ubuntu/logs/eval_mbart50_ft_wtags.hyp"
      ]
    },
    {
      "name": "Python: del_tags",
      "type": "python",
      "request": "launch",
      "program": "/home/ubuntu/fairseq/Kg2text/data_utils/del_tags.py",
      "console": "integratedTerminal",
      "args": [
        "--load_file",
        "/home/ubuntu/logs/decoded_result_kgpt_wtags.txt",
        "--save_file",
        "/home/ubuntu/logs/decoded_results/test.txt",
        "--tags_to_del",
        "[en_XX]"
      ]
    },
    {
      "name": "Python: aws server: triple_ent_debug",
      "type": "python",
      "request": "launch",
      "program": "/home/ubuntu/fairseq/fairseq/data/triple_ent_debug.py",
      "console": "integratedTerminal"
    },
    {
      "name": "Python: fairseq_generate_test_debug",
      "type": "python",
      "request": "launch",
      "program": "~/efs-storage/workspaces/hoverboard/fairseq/fairseq_cli/generate.py",
      "console": "integratedTerminal",
      "justMyCode": false,
      "args": [
        "~/efs-storage/data-bin/iwslt14.tokenized.de-en",
        "--path",
        "~/efs-storage/checkpoints/wmt14.en-fr.fconv-py/checkpoint_best.pt",
        "--beam",
        "5",
        "--remove-bpe"
      ]
    },
    {
      "name": "Python: translation_task",
      "type": "python",
      "request": "launch",
      "program": "/home/ubuntu/fairseq/fairseq_cli/train.py",
      "console": "integratedTerminal",
      "args": [
        "/home/ubuntu/efs-storage/data-bin/webnlg/data_mbart50_wtags",
        "--encoder-normalize-before",
        "--decoder-normalize-before",
        "--arch",
        "mbart_large",
        "--task",
        "translation",
        "--save-dir",
        "/home/ubuntu/efs-storage/checkpoint/mbart50_mbart50_finetune_webnlg_wtags_debug",
        "--source-lang",
        "input",
        "--target-lang",
        "label",
        "--criterion",
        "label_smoothed_cross_entropy",
        "--label-smoothing",
        "0.2",
        "--dataset-impl",
        "mmap",
        "--optimizer",
        "adam",
        "--adam-eps",
        "1e-06",
        "--adam-betas",
        "(0.9, 0.98)",
        "--lr-scheduler",
        "polynomial_decay",
        "--lr",
        "3e-05",
        "--stop-min-lr",
        "-1",
        "--warmup-updates",
        "2500",
        "--max-update",
        "40000",
        "--total-num-update",
        "40000",
        "--dropout",
        "0.3",
        "--attention-dropout",
        "0.1",
        "--weight-decay",
        "0.0",
        "--max-tokens",
        "256",
        "--update-freq",
        "2",
        "--save-interval",
        "1",
        "--save-interval-updates",
        "8000",
        "--keep-interval-updates",
        "10",
        "--no-epoch-checkpoints",
        "--seed",
        "222",
        "--log-format",
        "simple",
        "--log-interval",
        "2",
        "--layernorm-embedding",
        "--ddp-backend",
        "no_c10d"
      ]
      //"--finetune-from-model",
      //"/home/ubuntu/efs-storage/models/mbart50.ft.nn/model_wtags/model.pt",
    },
    {
      "name": "Python: prepare_fairseq_dataset",
      "type": "python",
      "request": "launch",
      "program": "./Kg2text/code/prepare_fairseq_dataset.py",
      "console": "integratedTerminal",
      "justMyCode": true,
      "args": [
        "--data",
        "test",
        "--option",
        "train",
        "--split",
        "train",
        "--encoder_type",
        "mbart50_wtags",
        "--decoder_type",
        "mbart50_wtags",
        "--tokenizer_src",
        "sentencepiece",
        "--tokenizer_tgt",
        "sentencepiece",
        "--vocab_file_src",
        "dict.mbart50_wtags.txt",
        "--vocab_file_tgt",
        "dict.mbart50_wtags.txt",
        "--experiment_comment",
        "mbart50_mbart50_wtags",
        "--pretrained_encoder_file",
        "mbart50_mbart50_encoder_wotags.pt",
        "--pretrained_decoder_file",
        "mbart50_mbart50_decoder_wotags.pt",
        "--prepend_src_lang_tag",
        "True",
        "--prepend_tgt_lang_tag",
        "True",
        "--src_length",
        "256",
        "--tgt_length",
        "108",
        "--seed",
        "0"
      ]
    },
    {
      "name": "Python: prepare_fairseq_dataset_wtags",
      "type": "python",
      "request": "launch",
      "program": "./Kg2text/code/prepare_fairseq_dataset.py",
      "console": "integratedTerminal",
      "justMyCode": true,
      "args": [
        "--data",
        "test",
        "--option",
        "train",
        "--split",
        "train",
        "--encoder_type",
        "mbart50_wtags",
        "--decoder_type",
        "mbart50_wtags",
        "--tokenizer_src",
        "sentencepiece",
        "--tokenizer_tgt",
        "sentencepiece",
        "--vocab_file_src",
        "dict.mbart50_wtags.txt",
        "--vocab_file_tgt",
        "dict.mbart50_wtags.txt",
        "--experiment_comment",
        "mbart50_mbart50_wtags",
        "--pretrained_encoder_file",
        "mbart50_mbart50_encoder_wtags.pt",
        "--pretrained_decoder_file",
        "mbart50_mbart50_decoder_wtags.pt",
        "--prepend_src_lang_tag",
        "True",
        "--prepend_tgt_lang_tag",
        "True",
        "--src_length",
        "256",
        "--tgt_length",
        "108",
        "--seed",
        "0"
      ]
    },
    {
      "name": "Python: Current File",
      "type": "python",
      "request": "launch",
      "program": "${file}",
      "console": "integratedTerminal"
    },
    {
      "name": "Python: fairseq_train_simple_lstm",
      "type": "python",
      "request": "launch",
      "program": "/home/xianjiay/efs-storage/workspaces/hoverboard/fairseq/fairseq_cli/train.py",
      "console": "integratedTerminal",
      "args": [
        "~/efs-storage/data-bin/iwslt14.tokenized.de-en",
        "--arch",
        "tutorial_simple_lstm",
        "--encoder-dropout",
        "0.2",
        "--decoder-dropout",
        "0.2",
        "--lr",
        "0.005",
        "--lr-shrink",
        "0.5",
        "--max-tokens",
        "12000",
        "--optimizer",
        "adam"
      ]
    },
    {
      "name": "Python: aws denoising_task",
      "type": "python",
      "request": "launch",
      "program": "/home/ubuntu/fairseq/fairseq_cli/train.py",
      "console": "integratedTerminal",
      "args": [
        "/local/home/ubuntu/efs-storage/data-bin/dataset_denoising/webnlg",
        "--encoder-normalize-before",
        "--decoder-normalize-before",
        "--arch",
        "mbart_large",
        "--task",
        "kg_multilingual_denoising",
        "--criterion",
        "label_smoothed_cross_entropy",
        "--label-smoothing",
        "0.2",
        "--dataset-impl",
        "mmap",
        "--optimizer",
        "adam",
        "--adam-eps",
        "1e-06",
        "--adam-betas",
        "(0.9, 0.98)",
        "--lr-scheduler",
        "polynomial_decay",
        "--lr",
        "3e-05",
        "--stop-min-lr",
        "-1",
        "--warmup-updates",
        "2500",
        "--max-update",
        "40000",
        "--total-num-update",
        "40000",
        "--dropout",
        "0.3",
        "--attention-dropout",
        "0.1",
        "--weight-decay",
        "0.0",
        "--max-tokens",
        "1024",
        "--update-freq",
        "2",
        "--save-interval",
        "1",
        "--save-interval-updates",
        "8000",
        "--keep-interval-updates",
        "10",
        "--no-epoch-checkpoints",
        "--seed",
        "222",
        "--log-format",
        "simple",
        "--log-interval",
        "2",
        "--reset-optimizer",
        "--reset-meters",
        "--reset-dataloader",
        "--reset-lr-scheduler",
        "--save-dir",
        "checkpoint/denoising_kgtext_wikidata",
        "--layernorm-embedding",
        "--ddp-backend",
        "no_c10d",
        "--langs",
        "en_XX",
        "--no-whole-word-mask-langs",
        "False",
        "--tokens-per-sample",
        "786",
        "--sample-break-mode",
        "eos",
        "--whole_word_mask_mode",
        "word",
        "--mask",
        "0.2",
        "--mask-random",
        "0.0",
        "--insert",
        "0.0",
        "--permute",
        "0.0",
        "--rotate",
        "0.0",
        "--poisson-lambda",
        "3.0",
        "--permute-sentences",
        "0.0",
        "--mask-length",
        "word",
        "--replace-length",
        "-1",
        "--shorten-method",
        "none",
        "--bpe",
        "sentencepiece",
        "--sentencepiece-model",
        "/home/ubuntu/efs-storage/tokenizer/mbart50/bpe/sentence.bpe.model",
        "--train-subset",
        "train",
        "--valid-subset",
        "valid"
      ]
    },
    {
      "name": "Python: clouddesk denoising_task",
      "type": "python",
      "request": "launch",
      "program": "/home/xianjiay/efs-storage/workspaces/hoverboard/fairseq/fairseq_cli/train.py",
      "console": "integratedTerminal",
      "args": [
        "/local/home/xianjiay/efs-storage/data-bin/dataset_denoising/webnlg",
        "--encoder-normalize-before",
        "--decoder-normalize-before",
        "--arch",
        "mbart_large",
        "--task",
        "kg_multilingual_denoising",
        "--criterion",
        "label_smoothed_cross_entropy",
        "--label-smoothing",
        "0.2",
        "--dataset-impl",
        "mmap",
        "--optimizer",
        "adam",
        "--adam-eps",
        "1e-06",
        "--adam-betas",
        "(0.9, 0.98)",
        "--lr-scheduler",
        "polynomial_decay",
        "--lr",
        "3e-05",
        "--stop-min-lr",
        "-1",
        "--warmup-updates",
        "2500",
        "--max-update",
        "40000",
        "--total-num-update",
        "40000",
        "--dropout",
        "0.3",
        "--attention-dropout",
        "0.1",
        "--weight-decay",
        "0.0",
        "--max-tokens",
        "1024",
        "--update-freq",
        "2",
        "--save-interval",
        "1",
        "--save-interval-updates",
        "8000",
        "--keep-interval-updates",
        "10",
        "--no-epoch-checkpoints",
        "--seed",
        "222",
        "--log-format",
        "simple",
        "--log-interval",
        "2",
        "--reset-optimizer",
        "--reset-meters",
        "--reset-dataloader",
        "--reset-lr-scheduler",
        "--save-dir",
        "checkpoint/denoising_webnlg",
        "--layernorm-embedding",
        "--ddp-backend",
        "no_c10d",
        "--langs",
        "en_XX",
        "--no-whole-word-mask-langs",
        "False",
        "--tokens-per-sample",
        "512",
        "--sample-break-mode",
        "eos",
        "--whole_word_mask_mode",
        "word",
        "--mask",
        "0.2",
        "--mask-random",
        "0.0",
        "--insert",
        "0.0",
        "--permute",
        "0.0",
        "--rotate",
        "0.0",
        "--poisson-lambda",
        "3.0",
        "--permute-sentences",
        "0.0",
        "--mask-length",
        "word",
        "--replace-length",
        "-1",
        "--shorten-method",
        "none",
        "--bpe",
        "sentencepiece",
        "--sentencepiece-model",
        "/home/xianjiay/efs-storage/tokenizer/mbart50/bpe/sentence.bpe.model",
        "--train-subset",
        "train",
        "--valid-subset",
        "valid"
      ]
    }
  ]
}